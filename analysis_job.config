[job_config]
name = Analysis job
action_on_failure = CONTINUE
analysis_script = run_pipeline_multiple_files.py
analysis_script_s3_location = s3://[YOUR-BUCKET]/scripts
analysis_script_local_location = source/spark_runner
upload_analysis_script = True

[spark_config]
driver_memory = 30g
executor_memory = 30g

[script_arguments]
input_location = s3://[YOUR-BUCKET]/...
output_location = s3://[YOUR-BUCKET]/...
annotation_file =
# Option for strand specificity is NONE|FIRST_READ_TRANSCRIPTION_STRAND|SECOND_READ_TRANSCRIPTION_STRAND
strand_specificity = NONE
run_picard = True
star_extra_args =
counter_extra_args = -t exon -g gene_name
picard_extra_args =
region = us-west-2
